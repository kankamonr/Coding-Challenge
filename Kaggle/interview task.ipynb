{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step of Implementation</h3>\n",
    "1. read file csv <br>\n",
    "2. convert lat lon to cartesian coordinate(use to cal area with radius in meters) <br>\n",
    "3. cal area of polygon, also area of point <br>\n",
    "4. cal the percentage of intersection <br>\n",
    "    &emsp;- if percentage of intersection >= 50% then that device in the polygon return IN <br>\n",
    "    &emsp;- if percentage of intersection  < 50% then the device not in the polygon return OUT <br>\n",
    "5. cal time in the polygon \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import library</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import math\n",
    "#import geoplot\n",
    "#import geoplot.crs as gcrs\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#import seaborn as sns\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lat/long to cartesian\n",
    "\n",
    "def get_cartesian(lat=None,lon=None):\n",
    "    lat, lon = np.deg2rad(lat), np.deg2rad(lon)\n",
    "    R = 6371000 # radius of the earth in meters\n",
    "    x = R * np.cos(lat) * np.cos(lon)\n",
    "    y = R * np.cos(lat) * np.sin(lon)\n",
    "    #z = R *np.sin(lat)\n",
    "    return x,y\n",
    "\n",
    "#print(get_cartesian(59.123818,14.608603))\n",
    "#print(get_cartesian(59.123814,14.608602))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Open the file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>convert_time</th>\n",
       "      <th>IN_OUT</th>\n",
       "      <th>Percentage_of_intersect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.123818</td>\n",
       "      <td>14.608603</td>\n",
       "      <td>1610723283</td>\n",
       "      <td>9.568983</td>\n",
       "      <td>2021-01-15 16:08:03</td>\n",
       "      <td>OUT</td>\n",
       "      <td>14.355902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.123818</td>\n",
       "      <td>14.608603</td>\n",
       "      <td>1610723284</td>\n",
       "      <td>9.568983</td>\n",
       "      <td>2021-01-15 16:08:04</td>\n",
       "      <td>OUT</td>\n",
       "      <td>14.368766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.123818</td>\n",
       "      <td>14.608603</td>\n",
       "      <td>1610723285</td>\n",
       "      <td>9.568983</td>\n",
       "      <td>2021-01-15 16:08:05</td>\n",
       "      <td>OUT</td>\n",
       "      <td>14.368766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.123814</td>\n",
       "      <td>14.608602</td>\n",
       "      <td>1610723286</td>\n",
       "      <td>12.046636</td>\n",
       "      <td>2021-01-15 16:08:06</td>\n",
       "      <td>OUT</td>\n",
       "      <td>10.757064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.123814</td>\n",
       "      <td>14.608602</td>\n",
       "      <td>1610723287</td>\n",
       "      <td>12.046636</td>\n",
       "      <td>2021-01-15 16:08:07</td>\n",
       "      <td>OUT</td>\n",
       "      <td>10.746673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.123872</td>\n",
       "      <td>14.608547</td>\n",
       "      <td>1610730736</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2021-01-15 18:12:16</td>\n",
       "      <td>IN</td>\n",
       "      <td>99.417883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.123870</td>\n",
       "      <td>14.608547</td>\n",
       "      <td>1610730765</td>\n",
       "      <td>3.809481</td>\n",
       "      <td>2021-01-15 18:12:45</td>\n",
       "      <td>IN</td>\n",
       "      <td>72.429529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.123889</td>\n",
       "      <td>14.608510</td>\n",
       "      <td>1610730806</td>\n",
       "      <td>3.025978</td>\n",
       "      <td>2021-01-15 18:13:26</td>\n",
       "      <td>IN</td>\n",
       "      <td>56.228028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.123901</td>\n",
       "      <td>14.608552</td>\n",
       "      <td>1610730872</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2021-01-15 18:14:32</td>\n",
       "      <td>IN</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.123868</td>\n",
       "      <td>14.608541</td>\n",
       "      <td>1610730887</td>\n",
       "      <td>2.755557</td>\n",
       "      <td>2021-01-15 18:14:47</td>\n",
       "      <td>IN</td>\n",
       "      <td>81.266088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude  longitude   timestamp  uncertainty         convert_time  \\\n",
       "hash_id                                                                       \n",
       "1        59.123818  14.608603  1610723283     9.568983  2021-01-15 16:08:03   \n",
       "1        59.123818  14.608603  1610723284     9.568983  2021-01-15 16:08:04   \n",
       "1        59.123818  14.608603  1610723285     9.568983  2021-01-15 16:08:05   \n",
       "1        59.123814  14.608602  1610723286    12.046636  2021-01-15 16:08:06   \n",
       "1        59.123814  14.608602  1610723287    12.046636  2021-01-15 16:08:07   \n",
       "...            ...        ...         ...          ...                  ...   \n",
       "2        59.123872  14.608547  1610730736     2.000000  2021-01-15 18:12:16   \n",
       "2        59.123870  14.608547  1610730765     3.809481  2021-01-15 18:12:45   \n",
       "2        59.123889  14.608510  1610730806     3.025978  2021-01-15 18:13:26   \n",
       "3        59.123901  14.608552  1610730872     2.000000  2021-01-15 18:14:32   \n",
       "2        59.123868  14.608541  1610730887     2.755557  2021-01-15 18:14:47   \n",
       "\n",
       "        IN_OUT  Percentage_of_intersect  \n",
       "hash_id                                  \n",
       "1          OUT                14.355902  \n",
       "1          OUT                14.368766  \n",
       "1          OUT                14.368766  \n",
       "1          OUT                10.757064  \n",
       "1          OUT                10.746673  \n",
       "...        ...                      ...  \n",
       "2           IN                99.417883  \n",
       "2           IN                72.429529  \n",
       "2           IN                56.228028  \n",
       "3           IN               100.000000  \n",
       "2           IN                81.266088  \n",
       "\n",
       "[2222 rows x 7 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path of the file to read\n",
    "#device_filepath = \"~/Documents/Kaggle/input/Interview_Task/dummy.csv\"\n",
    "\n",
    "# Read the file into a variable device data\n",
    "device_data = pd.read_csv(\"dummy2.csv\", index_col=0, parse_dates=True)\n",
    "#device_data[\"convert_timestamp\"] = \"\"\n",
    "#device_data.to_csv(\"dummy.csv\", index=True)\n",
    "device_data[\"IN_OUT\"] = IN_OUT\n",
    "device_data[\"Percentage_of_intersect\"] = percentage_of_intersect\n",
    "#print(device_data[\"latitude\"])\n",
    "device_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import namedtuple\n",
    "from shapely.geometry import Polygon, LinearRing, Point\n",
    "\n",
    "coordinate_polygon = []\n",
    "\n",
    "\n",
    "with open('outline.geojson') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "#extract nested list of coordinates\n",
    "for feature in data['features']:\n",
    "    for list in feature['geometry']['coordinates']:\n",
    "        for point in list:\n",
    "        \n",
    "            point= tuple(point)\n",
    "            #convert lat lon to catesian\n",
    "            point = get_cartesian(point[1],point[0])\n",
    "            coordinate_polygon.append(point)\n",
    "            \n",
    "        #print(coordinate_polygon)   \n",
    "#r = LinearRing(coordinate_polygon)\n",
    "\n",
    "polygon = Polygon(LinearRing(coordinate_polygon))\n",
    "#print(\"S: \",polygon)\n",
    "#print(\"Area: \", polygon.area)\n",
    "#print(convert_latx[0])\n",
    "check_inout = []\n",
    "check_inout.append(\"IN_OUT\")\n",
    "\n",
    "for i in range(1,(len(convert_latx))):\n",
    "    point = Point(convert_latx[i], convert_lony[i]).buffer((float(radius[i])))\n",
    "    check_inout.append(point.within(polygon))\n",
    "#print(check_inout)\n",
    "point = Point(convert_latx[28], convert_lony[28]).buffer((float(radius[28])))\n",
    "#check_inout.append(point.within(polygon))\n",
    "print(point.within(polygon))\n",
    "point2 = Point(convert_latx[28], convert_lony[28])\n",
    "print(point2.within(polygon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert timestamp to date time and lat,lon</h3>\n",
    "    &emsp;- convert timestamp to date time <br>\n",
    "    &emsp;- convert latitude and longitude to cetesian degree(in meter) and store lat and lon in diffrerent variable\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.568983397386681\n"
     ]
    }
   ],
   "source": [
    "#Convert timestamp to date time\n",
    "from csv import reader\n",
    "from datetime import datetime\n",
    "\n",
    "convert_timestamp = []\n",
    "convert_latlon = []\n",
    "radius = []\n",
    "convert_latx = []\n",
    "convert_lony = []\n",
    "\n",
    "# open file in read mode\n",
    "with open('dummy.csv', 'r') as read_obj:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(read_obj)\n",
    "    header = next(csv_reader)\n",
    "    convert_timestamp.append(\"convert_time\")\n",
    "    #convert_latlon.append(\"convert_point\")\n",
    "    #convert_latx.append(\"convert_latX\")\n",
    "    #convert_lony.append(\"convert_lonY\")\n",
    "    #radius.append(\"radius\")\n",
    "    \n",
    "    \n",
    "    if header != None:\n",
    "    # Iterate over each row in the csv using reader object\n",
    "        for row in csv_reader:\n",
    "            #print(row)\n",
    "        # row variable is a list that represents a row in csv\n",
    "            timestamp = datetime.fromtimestamp((int (row[3])))\n",
    "            \n",
    "            convert_timestamp.append(timestamp)\n",
    "            #print(convert_timestamp[1])\n",
    "            #print(len(convert_timestamp))\n",
    "            \n",
    "            convert_point = get_cartesian((float(row[1])),(float(row[2])))\n",
    "            convert_latlon.append(convert_point)\n",
    "            radius.append(row[4])\n",
    "        \n",
    "    for x in range(len(convert_latlon)):\n",
    "            \n",
    "        convert_latx.append((float(convert_latlon[x][0])))\n",
    "        #print(convert_latx)\n",
    "        convert_lony.append((float(convert_latlon[x][1])))\n",
    "    #print(convert_lony[1])\n",
    "    print(radius[1])\n",
    "    #print(convert_latx)            \n",
    "    \n",
    "#add conver timestamp to new file\n",
    "\n",
    "#with open('dummy.csv', 'r') as ifile :\n",
    " #   with open('dummy2.csv', 'w') as ofile:\n",
    "  #      for line, new in zip(ifile, convert_timestamp):\n",
    "   #         new_line = line.rstrip('\\n') + ',' + str(new) + '\\n'\n",
    "    #        ofile.write(new_line)\n",
    "        \n",
    "#device_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create circle from point\n",
    "circle_from_point = []\n",
    "area_circle = []\n",
    "intersect_area = []\n",
    "percentage_of_intersect = []\n",
    "#add header\n",
    "#circle_from_point.append(\"Circle\")\n",
    "#area_circle.append(\"Circle_area\")\n",
    "#intersect_area.append(\"Intersec_area\")\n",
    "#percentage_of_intersect.append(\"percentage_of_intersect\")\n",
    "\n",
    "for i in range(len(convert_latx)):\n",
    "    \n",
    "    circle = Point((float(convert_latx[i])), (float(convert_lony[i]))).buffer((float(radius[i])))\n",
    "    area = circle.area\n",
    "    circle_from_point.append(circle)\n",
    "    area_circle.append(area)\n",
    "    #intersect_circle = circle_from_point.intersection(polygon).area\n",
    "    #intersect_percent = intersect_area/a.area*100\n",
    "    #intersec_area.append(intersect_circle)\n",
    "    #percentage_of_intersect.append(intersect_percent)\n",
    "\n",
    "for i in range(len(area_circle)):\n",
    "    point_circle = circle_from_point[i]\n",
    "    intersect_circle = point_circle.intersection(polygon).area\n",
    "    percentage_intersect = intersect_circle/point_circle.area*100\n",
    "    intersect_area.append(intersect_circle)\n",
    "    percentage_of_intersect.append(percentage_intersect)\n",
    "    \n",
    "\n",
    "#print(percentage_of_intersect)\n",
    "\n",
    "\n",
    "#add conver timestamp to new file\n",
    "#with open('dummy2.csv', 'r') as ifile :\n",
    " #   with open('dummy3.csv', 'w') as ofile:\n",
    "  #      for line, new in zip(ifile, percentage_of_intersect):\n",
    "   #         new_line = line.rstrip('\\n') + ',' + str(new) + '\\n'\n",
    "    #        ofile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:  1892\n",
      "OUT:  330\n"
     ]
    }
   ],
   "source": [
    "IN_OUT = []\n",
    "#IN_OUT.append(\"IN_OUT\")\n",
    "for i in range(len(percentage_of_intersect)):\n",
    "    if percentage_of_intersect[i] >= 50:\n",
    "        IN_OUT.append(\"IN\")\n",
    "    else:\n",
    "        IN_OUT.append(\"OUT\")\n",
    "#print(IN_OUT)\n",
    "print(\"IN: \", IN_OUT.count(\"IN\"))\n",
    "print(\"OUT: \", IN_OUT.count(\"OUT\"))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dummy3.csv', 'r') as ifile :\n",
    "    with open('dummy4.csv', 'w') as ofile:\n",
    "        for line, new in zip(ifile, IN_OUT):\n",
    "            new_line = line.rstrip('\\n') + ',' + str(new) + '\\n'\n",
    "            ofile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line, new in zip(ifile, convert_latx):\n",
    "            new_line = line.rstrip('\\n') + ',' + str(new) + '\\n'\n",
    "            ofile.write(new_line)\n",
    "        for line, new in zip(ifile, convert_lony):\n",
    "            new_line = line.rstrip('\\n') + ',' + str(new) + '\\n'\n",
    "            ofile.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('dummy4.csv', delimiter=',')\n",
    "df.sort_values(by=['IN_OUT', 'convert_time'])\n",
    "#result = df.sort_values(['hash_id', 'convert_time'], ascending=[1, 0])\n",
    "\n",
    "#df = df.sort_values(['hash_id', 'convert_time'], ascending=[True, True]) # parameter ascending is applied to 'col1' and 'col2' respectively.\n",
    "\n",
    "df.to_csv('sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sorted.csv', delimiter=',')\n",
    "df.sort_values(by=['hash_id', 'convert_time'])\n",
    "#result = df.sort_values(['hash_id', 'convert_time'], ascending=[1, 0])\n",
    "\n",
    "#df = df.sort_values(['hash_id', 'convert_time'], ascending=[True, True]) # parameter ascending is applied to 'col1' and 'col2' respectively.\n",
    "\n",
    "df.to_csv('sorted2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
